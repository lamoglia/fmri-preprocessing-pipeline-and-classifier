# this scripts reads metadata from
# site_params.csv : metadata about each abide site
# subject_params.csv : metadata about each abide subject fmri file (built using data_extractor_from_raw_fmri)
# abide_participants_phenotype.csv : metadata about each abide subject (including ASD/TC classification) (generated by phenotypic-data-extractor)
# and then generates a single output file with all data each subject needs to run in preprocessing and classification

# this output file can be used to filter a subset of subject for experimentation and classification

import pandas as pd
import os

# site params obtained from abide
site_parameters_df = pd.read_csv("data/in/site_params.csv", sep=",", header=0)

SLICE_TIMING_OUT_DIR = "data/out/slice_timing"
SLICE_ORDER_OUT_DIR = "data/out/slice_order"

# subject params obtained from abide frmi files
subject_parameters_df = pd.read_csv("data/in/subject_params.csv", sep=";", header=0)

subject_parameters_phenotype = pd.read_csv("data/in/abide_participants_phenotype.csv", sep=",", header=0)


# iterate over subject_parameters_phenotype
def create_slice_timing_file(slice_timing, file_name):
    # if file exists, reteurn
    if os.path.exists(file_name):
        return

    slice_timing = slice_timing.replace("[", "").replace("]", "").replace(" ", "").split(",")
    with open(file_name, "w") as f:
        for item in slice_timing:
            f.write("%s\n" % item)

# iterate over subject_parameters_phenotype
def create_slice_order_file(slice_timing_str, file_name):
    if os.path.exists(file_name):
        return

    slice_timing_arr = slice_timing_str.replace("[", "").replace("]", "").replace(" ", "").split(",")
    slice_timing_arr_float = [float(i) for i in slice_timing_arr]

    slice_timing_arr_float_sorted = sorted(slice_timing_arr_float)

    output = []

    for i in range(len(slice_timing_arr_float)):
        index = slice_timing_arr_float_sorted.index(slice_timing_arr_float[i])
        output.append(index+1)

    with open(file_name, "w") as f:
        for item in output:
            f.write("%s\n" % item)

df = pd.DataFrame(
    columns=[
        "abide_version",
        "site",
        "sub_id",
        "group",
        "age",
        "sex",
        "full_iq",
        "tr_seconds",
        "slice_timing_file",
        "total_volumes",
        "functional_fmri_file",
        "anatomical_fmri_file",
        "total_voxels"
    ]
)

# iterate over each element in list
for index, row in subject_parameters_phenotype.iterrows():
    abide_version = row["abide_version"]
    site = row["site"]
    sub_id = row["sub_id"]
    group = row["group"]
    age = row["age"]
    sex = row["sex"]
    full_iq = row["full_iq"]

    print(f"Processing {abide_version} {site} {sub_id}")

    # get subject_parameters_df were version = abide_version
    filtered_subject_parameters = subject_parameters_df[subject_parameters_df["version"] == abide_version]
    filtered_subject_parameters = filtered_subject_parameters[filtered_subject_parameters["site"] == site]
    if abide_version == "ABIDE1":
        padded_sub_id = f"{sub_id:07}"
        filtered_subject_parameters = filtered_subject_parameters[filtered_subject_parameters["sub"] == f"sub-{padded_sub_id}"]
    else:
        filtered_subject_parameters = filtered_subject_parameters[filtered_subject_parameters["sub"] == f"sub-{sub_id}"]

    if filtered_subject_parameters.empty:
        print(f"Subject not found in {abide_version} {site} {sub_id}")
        continue

    tr_seconds = filtered_subject_parameters["tr_seconds"].values[0]
    total_volumes = filtered_subject_parameters["volumes"].values[0]
    functional_fmri_file = filtered_subject_parameters["file"].values[0]

    anatomical_fmri_file = ""
    if abide_version == "ABIDE1":
        anatomical_fmri_file = f"ABIDE1/raw/BIDS/{site}/sub-{padded_sub_id}/anat/sub-{padded_sub_id}_T1w.nii.gz"
    else:
        #will work because sessions other than 1 (ses-1) are being ingored.
        anatomical_fmri_file = f"ABIDE2/raw/ABIDEII-{site}/sub-{sub_id}/ses-1/anat/sub-{sub_id}_ses-1_run-1_T1w.nii.gz"

    filtered_site_parameters = site_parameters_df[site_parameters_df["version"] == abide_version]
    filtered_site_parameters = filtered_site_parameters[filtered_site_parameters["site"] == site]

    #CALCULATE TOTAL VOXELS
    image_size = filtered_subject_parameters["image_size"].values[0]
    volumes = filtered_subject_parameters["volumes"].values[0]

    split_image_size = image_size.split("x")
    total_voxels = int(split_image_size[0]) * int(split_image_size[1]) * int(split_image_size[2]) * int(volumes)

    slice_timing = filtered_site_parameters["SliceTiming"].values[0]
    # check if slice_timing is empty or null
    if pd.isnull(slice_timing) or slice_timing == "":
        print(f"Slice timing is null for {abide_version} {site} {sub_id}")
        continue

    slice_timing_filename = f"{abide_version}_{site}_slice_timing.txt"
    slice_order_filename = f"{abide_version}_{site}_slice_order.txt"
    create_slice_timing_file(slice_timing, f"{SLICE_TIMING_OUT_DIR}/{slice_timing_filename}")
    create_slice_order_file(slice_timing, f"{SLICE_ORDER_OUT_DIR}/{slice_order_filename}")

    # add a line to df
    df = pd.concat(
        [
            df,
            pd.DataFrame(
                [
                    {
                        "abide_version": abide_version,
                        "site": site,
                        "sub_id": sub_id,
                        "group": group,
                        "age": age,
                        "sex": sex,
                        "full_iq": full_iq,
                        "tr_seconds": tr_seconds,
                        "slice_timing_file": slice_timing_filename,
                        "total_volumes": total_volumes,
                        "functional_fmri_file": functional_fmri_file,
                        "anatomical_fmri_file": anatomical_fmri_file,
                        "total_voxels": total_voxels
                    }
                ]
            ),
        ],
        ignore_index=True,
    )

df.to_csv("data/out/preproc_params.csv", index=False)
